<!DOCTYPE html>
<html lang="en">
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="UTF-8">
    <title>terraform</title>
    <style>
        body {
            font-family: "SF Pro Display", system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue";
            max-width: 480px;
            margin: 0 auto;
            font-size: 13px;
        }
        pre {
            border: 1px solid black;
            overflow-x: auto;
        }
        h2 > a {
            color: black;
            text-decoration: none;
        }
        h2 > a:hover {
            text-decoration: underline;
        }
        h2 > a:visited {
            color: black;
        }

        a:visited {
            color: blue;
        }

        .important {
            background-color: lightgray;
            padding: 1em
        }

        .chapter {
            font-style: italic;

        }
    </style>
</head>
<body>
<hr>
<p class='important'>
notes on ðŸ“– oreilly's book: <i>Terraform: Up and Running, 3rd Edition By
Yevgeniy Brikman</i>
</p>
<h1 id='top'>~ terraform</h1>
<a href='#table'>table of contents</a>
<h2 id='why'>why terraform?</h2>
<p>
First, let me state that it is better to manage a big fleet of servers using
code, you can have version control, which honestly seems to be reason enough to
consider it.
</p>

<p>
Before things like terraform, developers worked with operation teams, to deploy
their code.  This usually was in baremetal systems, where sysadmins had to take
care of installing dependencies, updating packages, deploying software, making
sure all the servers had the same (similarish) configurations, among other
stuff.
</p>

<p>
This caused a lot of issues, since things can get messy real quickly.
Therefore, developers came with the solution, of configuring, deploying and
doing pretty much everything with code. This can be done multiple ways, here I
list a few.
</p>
<ul>
  <li>
    <p>ad hoc scripts</p>
    <ul>
      <li>
        You write scripts in your favorite scripting language to install
        programs, update stuff and so on.
      </li>
      <li>
        Better than doing it on the fly, but, still have some issues, for
        example is hard to be consistent on all your scripts,  when multiple
        developers will be working on them.
      </li>
    </ul>
  </li>
  <li>
    <p>configuration management tools</p>
    <ul>
      <li>
        Stuff like <i>`ansible`</i>, tools that are designed to manage software
        on existing servers.
      </li>
      <li>
        Improvement compared with the ad hoc scripts, since this will be way
        more consistent, not only on your project but on multiple projects on
        different organizations.
      </li>
      <li>
        Other thing that make them a bit better than the ad hoc scripts, is
        that you can manage multiple heards of servers this way. With the ad
        hoc scripts you usually need to ssh to the system and run it or do
        something similar, with ansible you can deploy software in multiple
        servers with one command.
      </li>
    </ul>
  </li>
  <li>
    <p>server templating tools</p>
    <ul>
      <li>
        Instead of launching a bunch of servers and deploying the software with
        the same script on each. You build an image, and create the servers
        with this image.
      </li>
      <li>
        If you need to update some package or something, you rebuild the image,
        destroy the running server and redeploy.
      </li>
    </ul>
  </li>
  <li>
    <p>provisioning tools</p>
    <ul>
      <li>
        Here is where <b>terraform</b> comes into the picture. These tools will
        literally create servers themselves.
      </li>
      <li>
        Wait, how would they do that? Are they humans that go to a lab and
        mount a server with their hands? No, they will talk with cloud
        providers APIs and create the resources you need.
      </li>
      <li>
        The neat part about this is that like k8s, they use the declarative
        approach. You declare the status of your infra, and it will create it
        like you have define it. If you have a terraform file that says we need
        to create 10  servers with certain image, and further down the line you
        want to add 5 more. You can change that file to say 15, and terraform
        will take care of just having 15 servers, not 25.
      </li>
      <li>
        Other cool stuff, is version control. You can have this configuration
        files pass through a code review process.
      </li>
    </ul>
  </li>
</ul>
<p>
So why terraform among other tools? Well, the author of the book presents some
good points.
</p>
</p>
<ul>
  <li>
    <p>Domain Specific Language</p>
    <ul>
      <li>
        For starters they have a Domain Specific Language. Meaning there is
        this HCL language that you will find in all the terraform config files.
        This is can be beneficial, since some tools use general languages like
        python meaning you lose consistency from project to project.
      </li>
    </ul>
  </li>
  <li>
    <p>Masterless</p>
    <ul>
      <li>
        Do not need a server to keep track of the state, since the <i>"master
        server"</i> is the Cloud Provider itself.
      </li>
    </ul>
  </li>
</ul>
<p>
The author make some other points, but this two are enough for me I guess.
</p>

<h2 id='using'>using terraform</h2>

<p>
In the book they use aws, so we will use it here too. Knowledge is somewhat
transferable to your cloud provider of choice, the thing is that different
cloud providers name stuff different, and also have different types of
resources. For example, <a
href='https://www.digitalocean.com/products/droplets'>digitalocean's
droplet</a> seem to be <a href='https://aws.amazon.com/ec2/features/'>aws
ec2</a>.
</p>

<p>
This means that names will change. So if you are using something different to
aws, this notes might help, but you will have to refer to some specific
declarations for your specific cloud provider.
</p>

<p>
So create an account, give your credit card info to jeff bezos, and lets start.
</p>

<p>
The account you just created is the root account for your aws, so you can do
anything with it. It makes sense to create another one with less privilege for
doing what we want in the book.
</p>

<p>
You manage your accounts on the IAM (Identity and Access Management) panel.
Create one and give it AdministratorAccess. Create an Access Key ID and a Secret
Access Key. Store them somewhere safe, and export the variables in your shell.
<pre>
$ export AWS_ACCESS_KEY_ID=(your access key id)
$ export AWS_SECRET_ACCESS_KEY=(your secret access key)
</pre>
</p>

<p>
One quick note, we will use the Default VPC for the book. A VPC is an isolated
area of your AWS account that has its own virtual network and ip address space.
</p>
<p>
Once you exported the <i>`env`</i> variables and installed terraform we can
continue to create our first <i>`tf`</i> file.
</p>
<h3>Deploying a Single Server</h3>
<p>
You will create a <i>`.tf`</i> file. This is files are written in the DSL for
terraform called HCL (hashicorp configuration language). It is the declarative
language we talked about a bit before.
</p>
<p>
First thing we usually do is specify the provider, so you go to the directory
where you will have your project and create a <i>`main.tf`</i> file with:
<pre>
provider "aws" {
  region = "us-east-2"
}
</pre>
</p>
<p>
We are telling terraform to use aws and that region.
</p>
<p>
Now, the syntax  will be pretty much the same for any provider, the thing that
will change is the types of resources you can create. Generally you will do
something like:
<pre>
resource "provider_resource" "name" {
    [config ...]
}
</pre>
</p>
<ul>
  <li>
    <p><b>provider</b>: this would be aws</p>
  </li>
  <li>
    <p>
      <b>resource</b>: this would the type of resource, in our case we will use
      <i>instance</i>, which is aws lingo for ec2 instance.
    </p>
  </li>
  <li>
    <p>
      <b>name</b>: identifier to use inside terraform. Will come handy when
      using expressions.
    </p>
  </li>
  <li>
    <p>
      <b>config</b>: resource specific config
    </p>
  </li>
</ul>

<p>
Okay so if we want to create a ec2 instance , with a specific ami (amazon
machine images) and with a name we will do something like:
<pre>
resource "aws_instance" "example" {
    # amazon machine image to run on the ec2 instance, this is an ubuntu 20.04
    ami = "ami-0fb653ca2d3203ac1"
    instance_type = "t2.micro"
    tags = {
        Name = "terraform-example"
    }
}
</pre>
</p>
<p>
We use <i>t2.micro</i>, which has one virtual CPU, 1 GB of memory, and is part
of the AWS Free Tier.
</p>

<p>
Okay now we have our file. How do we actually deploy this on aws? Well here are
some verbs.
</p>
<ul>
  <li>
    <p>
      <b>terraform init</b>: this will scan the code, check which
      providers we will be using and download the code for them. Everything is
      put under the <i>`.terraform`</i> directory.
    </p>
  </li>
  <li>
    <p>
      <b>terraform plan</b>: show you what terraform will do without actually
      doing it. Similar to a git diff on the format.
    </p>
  </li>
  <li>
    <p>
      <b>terraform apply</b>: shows the plan and ask you to confirm it. If you
      type <i>yes</i> it will talk with the providers and actually create the
      stuff.
    </p>
  </li>
</ul>
<p>
Remember terraform already knows what resources have been created. So if we
update the resource, it will update the one we already created. Or if the
update needs to destroy and recreate it will do that too.
</p>
<p>
Last step, add this to your git repo. Here is a quick <i>`.gitignore`</i>
<pre>
.terraform
*.tfstate
*.tfstate.backup
</pre>
</p>
<h3>Deploying a web server</h3>
<p>
So usually you would build an image with <a
href='https://www.packer.io/'>packer</a> upload it to <i>ami</i> and tell the
resource to use that image. Since this is a quick example, we are going to use
a web server that comes already with ubuntu 20.04.
</p>
<p>
You have the option of passing shell scripts on the <i>user_data</i> config
variable on the resource, so we will take advantage of this to tell our ubuntu
to start the web server.
<pre>
resource "aws_instance" "example" {
    # amazon machine image to run on the ec2 instance, this is an ubuntu 20.04
    ami = "ami-0fb653ca2d3203ac1"
    instance_type = "t2.micro"

    # we would usually create an AMI for this with a real web app, using rails
    # or smth, but this is just a simple example.
    user_data = <<-EOF
              #!/bin/bash
              echo "Hello, World" > index.html
              nohup busybox httpd -f -p 8080 &
              EOF

    user_data_replace_on_change = true

    tags = {
        Name = "terraform-example"
    }
}
</pre>
</p>

<p>
On the user_data we are sending the commands to start the server. Also note the
<i>`user_data_replace_on_change`</i>. This tells terraform to destroy the
instance and start it again if user data changes. Which is the case, so if now
you run <i>terraform apply</i>, aws will show that the first resource was
terminated and that a new one started running.
</p>
<p>
<i>Ojito</i> (Spanish for pay attention), we are not going to be able to make
an http request to the server due to  aws not allowing any incoming or outgoing
traffic from an ec2 instance.
</p>
<p>
We need to create a new resource for this called <i>`security_group`</i>. So in
the same file we will add:
<pre>
resource "aws_security_group" "instance" {
    name = "terraform-example-instance"

    ingress {
        from_port = 8080
        to_port = 8080
        protocol = "tcp"
        cidr_blocks = ["0.0.0.0/0"]
    }
}
</pre>
</p>
<p>
This basically tells aws to accept traffic on port 8080, but we need to tell
our ec2 instance to use this resource.
</p>
<p>
So terraform has expressions, which is anything that return a value, one type
is a <i>`reference`</i>, which allows you to access values from other parts of
the code. For example for the security group we just created we can call it
saying: <i>`aws_security_group.instance.id`</i>
</p>
<p>
They call this <b>resource attribute reference</b> the syntax is
<pre>
PROVIDER_TYPE.NAME.ATTRIBUTE
</pre>
</p>
<p>
So now we need to add in our ec2 resource
<pre>
vpc_security_group_ids = [aws_security_group.instance.id]
</pre>
</p>
<p>
Adding this we are creating an <i>`implicit dependency`</i> meaning the order
in which we create the stuff matters. You can render a graph for this using
<pre>
$ terraform graph | dot -Tsvg > output.svg
</pre>
</p>
<p>
You need to have <i>`graphviz`</i> installed though
</p>

<h3>Variables</h3>

<p>
You may want to have variables in your configuration. Maybe a port, a token, or
something that you want to pass around. There is the <i>`variable`</i>
identifier for this exact reason.
<pre>
# hostname is the variable name
variable "hostname" {
    description = "something useful for you and your teammates"
    type = "string" # this can be number, bool, list, map, set, object, tuple
    default = "domain.do.com" # the default value if you do not pass anything
}
</pre>
</p>

<p>
There are more options you have
<ul>
  <li>
    <p>
      <b>default</b>: if you do not put this, and do not send the variable in
      the environment or in the CLI, terraform will stop and ask you to input
      it.
    </p>
  </li>
  <li>
    <p>
      <b>validation</b>: if you want some custom checks on the variable, so
      enforcing min or max values.
    </p>
  </li>
  <li>
    <p>
      <b>sensitive</b>: if this is set to true terraform will not log it when
      you run <i>`plan`</i> or <i>`apply`</i>
    </p>
  </li>
</ul>
</p>

<p>
You can also create objects, like python's dicts or ruby hashes.
<pre>
variable "object_example" {
  description = "An example of a structural type in Terraform"
  type        = object({
    name    = string
    age     = number
    tags    = list(string)
    enabled = bool
  })

  default = {
    name    = "value1"
    age     = 42
    tags    = ["a", "b", "c"]
    enabled = true
  }
}
</pre>
</p>

<p>
Once you define it you can send the variables via de command line the
<i>`-var`</i> flag
<pre>
terraform plan -var "server_port=8080"
</pre>
Or you could also just export the variable with the <i>`TF_VAR_name`</i>
format. For example:
<pre>
$ export TF_VAR_server_port=8080
$ terraform plan
</pre>
</p>

<p>
Now it is likely that you want to call it inside your file right? You can do
that by using <i>`var.variable_name`</i>. (e.g.  <i>`var.server_port`</i>). Or
if you want to use it inside a string, you can wrap it with
<code>"${var.server_port}"</code>
</p>

<h4>Output Variables</h4>

<p>
There is this other type of variables that are not for using them inside your
file, but for them to display information that was created when running the
terraform scripts. They are good for return info useful to you, say for example
the public  ip of an object you just created.

<pre>
output "public_ip" {
  value = aws_instance.example.public_ip
}
</pre>
<p>

<p>
When you run the <i>`terraform apply`</i> you would see it render at the end
<pre>
Outputs:

public_ip = "1.2.3.4"
</pre>
You can also render them with <i>`terraform output`</i>, or more specific even
with <i>`terraform output public_ip`</i>.
</p>

<h3>Deploying a Cluster of EC2s</h3>
<p>
One ec2 is great. You know what is better? a cluster of ec2's that can scale
automatically based on the usage of the application. AWS got you covered with
the <i>aws_autoscaling_group</i>. An Auto Scaling Group contains a collection
of EC2 instances that are treated as a group for the purposes of scaling and
management.
</p>

<p>
What we are going to do is just taking one of the ec2 instances we created,
move the definition to an <i>aws_launch_template</i>, change the name of a few
parameters and tell the asg to use that ec2 template.
</p>

<p class='important'>
Do note, that we are not using <i>`aws_launch_configuration`</i> like in the
book. Seems to be deprecated, and if you try to use it aws's api will probably
complain that you do not have permission to do that. <a
href='https://docs.aws.amazon.com/autoscaling/ec2/userguide/launch-configurations.html'>More
info</a>.
</p>

<p>
The template will look something like this:
<pre>
resource "aws_launch_template" "example" {
    name_prefix   = "example-"
    image_id = "ami-0fb653ca2d3203ac1"
    instance_type = "t2.micro"

    vpc_security_group_ids = [aws_security_group.instance.id]

    user_data = base64encode(<<-EOF
              #!/bin/bash
              echo "Hello, World" > index.html
              nohup busybox httpd -f -p ${var.server_port} &
              EOF
    )
}
</pre>
</p>
<p>
There are this things, called <i>data sources</i> which will query the cloud
providers api and get some info, in this case we want to query it to get the
subnet we are going to use to deploy the ec2 on.
<pre>
# we need to tell the asg which subnet to use, this data source  will return
# the the default vpc in our aws account, which then we will use to query for
# the subnets.
data "aws_vpc" "default" {
    default = true
}

data "aws_subnets" "default" {
    filter {
        name = "vpc-id"
        values = [data.aws_vpc.default.id]
    }
}
</pre>
</p>

<p>
Mind how I am using the data source inside the other data source, that is how
you call them: <b>data.aws_vpc.default.id</b>
</p>

<p>
Now the actual asg definition with min size of 2 ec2s and max of 10, would look
like this:
<pre>
resource "aws_autoscaling_group" "example" {

    launch_template {
        id = aws_launch_template.example.id
        version = "$Latest" # Template version. Can be version number
    }

    # which subnet should asg use? we get this from the data sources.
    vpc_zone_identifier = data.aws_subnets.default.ids

    min_size = 2
    max_size = 10

    tag {
        key = "Name"
        value = "terraform-asg-example"
        propagate_at_launch = true
    }

}
</pre>
</p>

<p>
So if you now do <i>`terraform apply`</i> the asg will be deployed and the ec2
instance will be deployed. Although we still have one piece missing. We need to
create a load balancer, if not we would have to talk directly to each ec2
instance. It would be nice to have a piece of software that selected which ec2
to use based on a healthcheck.
</p>
<p>
Well, once again, aws got you covered. There is this resource, <i>`aws_lb`</i>
that is a load balancer. There are different types of load balancer, different
ones interact with different layers of the OSI model (ALB, NLB). We are going
to use ALB which interacts with the layer 7.
</p>
<p>
Need to define the ALB
<pre>
resource "aws_lb" "example" {
    name = "terraform-asg-example"
    load_balancer_type = "application"
    subnets = data.aws_subnets.default.ids
}
</pre>
</p>
<p>
It comes down to defining three things.
</p>
<ul>
  <li>
    <p>
      <b>listener</b> this is where we actually tell it to which port it should
      listen
      <pre>
# configure the aws_lb to listen to port 80 and use http
resource "aws_lb_listener" "http" {
    load_balancer_arn = aws_lb.example.arn
    port = 80
    protocol = "HTTP"

    # send 404 to requests that do not match any listener rules.
    default_action {
        type = "fixed-response"

        # by default, return just a 404
        fixed_response {
            content_type = "text/plain"
            message_body = "404: page not found"
            status_code  = 404

        }
    }
}
      </pre>
    </p>
  </li>
  <li>
    <p>
        <b>listener rule</b> this is where we map a pattern to a  target group
    <pre>
resource "aws_lb_listener_rule" "asg" {
    listener_arn = aws_lb_listener.http.arn
    priority = 100

    # match any path...
    condition {
        path_pattern {
            values = ["*"]
        }
    }

    # ...and send it to our asg group
    action {
        type = "forward"
        target_group_arn = aws_lb_target_group.asg.arn
    }
}
    </pre>
      You will notice that we have not defined the target_group, we will do it
      in the next step
    </p>
  </li>
  <li>
    <p>
        <b>target group</b> here we define a health check for the instances.
        Take into account we are not defining which ec2 instances to send the
        traffic to here. Instead we are going to do it in the asg definition.
        <pre>
# Health checks your instances by periodically sending an HTTP request to each
# ec2. If one becomes unhealthy will stop sending the traffic to it.
#
# Ojito, we are not defining which ec2 instances to send requests to
# here. That will be done in aws_autoscaling_group using the parameter
# aws_lb_target_group_attachment.
resource "aws_lb_target_group" "asg" {
  name     = "terraform-asg-example"
  port     = var.server_port
  protocol = "HTTP"
  vpc_id   = data.aws_vpc.default.id

  health_check {
    path                = "/"
    protocol            = "HTTP"
    matcher             = "200"
    interval            = 15
    timeout             = 3
    healthy_threshold   = 2
    unhealthy_threshold = 2
  }
}
        </pre>
    </p>
  </li>
</ul>
<p>
For the full example go to <a
href='https://github.com/bsantanad/terraform.oreilly/blob/main/asg.ec2.tf'>github
asg.ec2.tf</a>.
</p>

<p>
Finally add this output variable so you have the dns
<pre>
output "alb_dns_name" {
    value = aws_lb.example.dns_name
    description = "dns of the load balancer"
}
</pre>
</p>

<h3>Cleanup</h3>

<p>
Anyway, we do not want to have this aws resources there for the rest of
eternity. Mostly because we already gave them our credit card. So once you
deployed this, and tested it. We can clean everything up.
</p>

<p>
<i>`terraform destroy`</i> will do the trick. There is no undo, but the good
thing is that you already have it in a file so you can destroy it and apply it
however many times you like.
</p>

<p>
So this -- according to the book -- are the basics of terraform. Now you can go
into the wild and start terraforming your favorite cloud provider. (Or you can
continue reading this, if I wrote my notes on more chapters)
</p>


<h3 id='table'>~ table of contents</h3>
<ul>
  <li><a href='#why'>why terraform?</a></li>
  <li><a href='#using'>using terraform</a></li>
</ul>

<p><a href='#top'>â†‘ go to the top</a></p>

</body>
</html>


